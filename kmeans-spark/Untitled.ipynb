{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pickle \n",
    "import sys \n",
    "import time\n",
    "from numpy.linalg import norm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of centroids\n",
    "K = 5  \n",
    "# Number of K-means runs that are executed in parallel. Equivalently, number of sets of initial points\n",
    "RUNS = 25  \n",
    "# For reproducability of results\n",
    "RANDOM_SEED = 60295531 \n",
    "# The K-means algorithm is terminated when the change in the \n",
    "# location of the centroids is smaller than 0.1\n",
    "converge_dist = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_log(s):\n",
    "    '''\n",
    "    Print progress logs\n",
    "    '''\n",
    "    sys.stdout.write(s + \"\\n\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def compute_entropy(d):\n",
    "    '''\n",
    "    Compute the entropy given the frequency vector `d`\n",
    "    '''\n",
    "    d = np.array(d)\n",
    "    d = 1.0 * d / d.sum()\n",
    "    return -np.sum(d * np.log2(d))\n",
    "\n",
    "\n",
    "def choice(p):\n",
    "    '''\n",
    "    Generates a random sample from [0, len(p)),\n",
    "    where p[i] is the probability associated with i. \n",
    "    '''\n",
    "    random = np.random.random()\n",
    "    r = 0.0\n",
    "    for idx in range(len(p)):\n",
    "        r = r + p[idx]\n",
    "        if r > random:\n",
    "            return idx\n",
    "    assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_init(rdd, K, RUNS, seed):\n",
    "    '''\n",
    "    Select `RUNS` sets of initial points for `K`-means++\n",
    "    '''\n",
    "    # the `centers` variable is what we want to return\n",
    "    n_data = rdd.count()\n",
    "    shape = rdd.take(1)[0][1].shape[0]\n",
    "    centers = np.zeros((RUNS, K, shape))\n",
    "    \n",
    "    def update_dist(vec, dist, k):\n",
    "        new_dist = norm(vec - centers[:, k], axis=1)**2\n",
    "        return np.min([dist, new_dist], axis=0)\n",
    "    # The second element `dist` in the tuple below is the\n",
    "    # closest distance from each data point to the selected\n",
    "    # points in the initial set, where `dist[i]` is the\n",
    "    # closest distance to the points in the i-th initial set\n",
    "    data = (rdd\n",
    "            .map(lambda p: (p, [np.inf] * RUNS)) \\\n",
    "            .cache())\n",
    "    # Collect the feature vectors of all data points\n",
    "    # beforehand, might be useful in the following\n",
    "    # for-loop\n",
    "    local_data = (rdd\n",
    "                    .map(lambda (name, vec): vec)\n",
    "                    .collect())\n",
    "    # Randomly select the first point for every run of\n",
    "    # k-means++, i.e. randomly select `RUNS` points\n",
    "    # and add it to the `centers` variable\n",
    "    sample = [local_data[k] for k in\n",
    "        np.random.randint(0, len(local_data), RUNS)]\n",
    "    centers[:, 0] = sample\n",
    "    for idx in range(K - 1):\n",
    "        ########################################################\n",
    "        # In each iteration, you need to select one point for\n",
    "        # each set of initial points (so select `RUNS` points\n",
    "        # in total). For each data point x, let D_i(x) be the\n",
    "        # distance between x and the nearest center that has\n",
    "        # already been added to the i-th set. Choose a new\n",
    "        # data point for i-th set using a weighted probability\n",
    "        # where point x is chosen with probability proportional\n",
    "        # to D_i(x)^2 . Repeat each data point by 25 times\n",
    "        # (for each RUN) to get 12140x25\n",
    "        ########################################################\n",
    "        #Update distance\n",
    "        data = (data\n",
    "            .map(lambda ((name,vec),dist):\n",
    "                    ((name,vec),update_dist(vec,dist,idx)))\n",
    "            .cache())\n",
    "        #Calculate sum of D_i(x)^2\n",
    "        d1 = data.map(lambda ((name,vec),dist): (1,dist))\n",
    "        d2 = d1.reduceByKey(lambda x,y: np.sum([x,y], axis=0))\n",
    "        total = d2.collect()[0][1]\n",
    "        #Normalize each distance to get the probabilities and\n",
    "        #reshapte to 12140x25\n",
    "        prob = (data\n",
    "            .map(lambda ((name,vec),dist):\n",
    "                np.divide(dist,total))\n",
    "            .collect())\n",
    "        prob = np.reshape(prob,(len(local_data), RUNS))\n",
    "        #K'th centroid for each run\n",
    "        data_id = [choice(prob[:,i]) for i in xrange(RUNS)]\n",
    "        sample = [local_data[i] for i in data_id]\n",
    "        centers[:, idx+1] = sample\n",
    "    return centers\n",
    "    # The second element `dist` in the tuple below is the\n",
    "    # closest distance from each data point to the selected\n",
    "    # points in the initial set, where `dist[i]` is the\n",
    "    # closest distance to the points in the i-th initial set\n",
    "    data = (rdd\n",
    "            .map(lambda p: (p, [np.inf] * RUNS)) \\\n",
    "            .cache())\n",
    "    # Collect the feature vectors of all data points\n",
    "    # beforehand, might be useful in the following\n",
    "    # for-loop\n",
    "    local_data = (rdd\n",
    "                    .map(lambda (name, vec): vec)\n",
    "                    .collect())\n",
    "    # Randomly select the first point for every run of\n",
    "    # k-means++, i.e. randomly select `RUNS` points\n",
    "    # and add it to the `centers` variable\n",
    "    sample = [local_data[k] for k in\n",
    "        np.random.randint(0, len(local_data), RUNS)]\n",
    "    centers[:, 0] = sample\n",
    "    for idx in range(K - 1):\n",
    "        ########################################################\n",
    "        # In each iteration, you need to select one point for\n",
    "        # each set of initial points (so select `RUNS` points\n",
    "        # in total). For each data point x, let D_i(x) be the\n",
    "        # distance between x and the nearest center that has\n",
    "        # already been added to the i-th set. Choose a new\n",
    "        # data point for i-th set using a weighted probability\n",
    "        # where point x is chosen with probability proportional\n",
    "        # to D_i(x)^2 . Repeat each data point by 25 times\n",
    "        # (for each RUN) to get 12140x25\n",
    "        ########################################################\n",
    "        #Update distance\n",
    "        data = (data\n",
    "                .map(lambda ((name,vec),dist):\n",
    "                        ((name,vec),update_dist(vec,dist,idx)))\n",
    "                .cache())\n",
    "        #Calculate sum of D_i(x)^2\n",
    "        d1 = data.map(lambda ((name,vec),dist): (1,dist))\n",
    "        d2 = d1.reduceByKey(lambda x,y: np.sum([x,y], axis=0))\n",
    "        total = d2.collect()[0][1]\n",
    "        #Normalize each distance to get the probabilities and  \n",
    "        # reshape to 12140x25\n",
    "        prob = (data\n",
    "            .map(lambda ((name,vec),dist):\n",
    "                    np.divide(dist,total))\n",
    "            .collect())\n",
    "        prob = np.reshape(prob,(len(local_data), RUNS))\n",
    "        #K'th centroid for each run\n",
    "        data_id = [choice(prob[:,i]) for i in xrange(RUNS)]\n",
    "        sample = [local_data[i] for i in data_id]\n",
    "        centers[:, idx+1] = sample\n",
    "    return centers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
